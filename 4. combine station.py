# å°‡å€‹åˆ¥ç«™é»è³‡æ–™æ•´åˆæˆæ‰€æœ‰ç«™é»åˆä½µçš„å¹´åº¦å‘¨è³‡æ–™
# åŸæœ¬: äºŒæ—å„ç©ºæ±™å› å­å€¼1-52å‘¨ã€å¤§é‡Œå„ç©ºæ±™å› å­å€¼1-52å‘¨...
# æ•´ç†å¾Œ: NO-æ‰€æœ‰ç«™é»1-52å‘¨çš„å€¼ã€PM25-æ‰€æœ‰ç«™é»1-52å‘¨çš„å€¼...
import os
import pandas as pd
import re

def process_interpolated_files_stationwise():
    input_dir = r'3_interpolated_output'
    output_base_dir = r'4_interpolated_yearly_stationwise'
    os.makedirs(output_base_dir, exist_ok=True)

    # è™•ç†å¹´ä»½ç¯„åœ
    years = range(2015, 2020)  # 2015~2019

    # ç§»é™¤"é›¢å³¶"
    areas = ['ä¸­éƒ¨', 'åŒ—éƒ¨', 'ç«¹è‹—', 'å®œè˜­', 'èŠ±æ±', 'é«˜å±', 'é›²å˜‰å—']

    # å¤šå€‹æ¸¬é …
    target_factors = ["NO", "NO2", "NOx", "O3", "PM10", "PM2.5", "SO2"]
    factor_filename_map = {f: f.replace('.', '') for f in target_factors}  # è™•ç† PM2.5 -> PM25 æª”åç”¨

    for factor in target_factors:
        output_factor_name = factor_filename_map[factor]

        for year in years:
            print(f'\nğŸ“… è™•ç† {year} å¹´ {factor} æ•¸æ“š...')
            dfs = []

            year_path = os.path.join(input_dir, str(year))
            if not os.path.exists(year_path):
                print(f"âš ï¸ è·¯å¾‘ä¸å­˜åœ¨ï¼š{year_path}")
                continue

            for area in areas:
                area_path = os.path.join(year_path, area)
                if not os.path.exists(area_path):
                    continue

                for filename in os.listdir(area_path):
                    if filename.endswith(".csv"):
                        file_path = os.path.join(area_path, filename)
                        try:
                            df = pd.read_csv(file_path, encoding='utf-8-sig')
                            df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')

                            # å¾æª”åæå–æ¸¬ç«™åç¨±
                            match = re.match(r"2_å‘¨çµ±è¨ˆ_å¹³å‡å€¼_(.+?)_\d{4}\.csv", filename)
                            if not match:
                                print(f"â“ ç„¡æ³•å¾æª”åæå–æ¸¬ç«™åç¨±: {filename}")
                                continue
                            station_name = match.group(1)

                            if factor in df.columns:
                                sub_df = df[['æ—¥æœŸ', factor]].copy()
                                sub_df.rename(columns={factor: station_name}, inplace=True)
                                dfs.append(sub_df)
                        except Exception as e:
                            print(f"âŒ éŒ¯èª¤è™•ç† {file_path}ï¼š{e}")

            # åˆä½µæ‰€æœ‰æ¸¬ç«™è©²æ¸¬é …çš„è³‡æ–™
            if dfs:
                merged_df = dfs[0]
                for df in dfs[1:]:
                    merged_df = pd.merge(merged_df, df, on='æ—¥æœŸ', how='outer')

                merged_df.sort_values('æ—¥æœŸ', inplace=True)

                # å„²å­˜è³‡æ–™å¤¾ç‚º interpolated_yearly_stationwise/NO/ã€PM25/ ç­‰
                factor_output_dir = os.path.join(output_base_dir, output_factor_name)
                os.makedirs(factor_output_dir, exist_ok=True)

                output_file = os.path.join(factor_output_dir, f"{output_factor_name}_merged_{year}.csv")
                merged_df.to_csv(output_file, index=False, encoding="utf-8-sig", na_rep='NaN')
                print(f"âœ… å·²è¼¸å‡ºï¼š{output_file}ï¼ˆå…± {len(merged_df)} ç­†ï¼‰")
            else:
                print(f"â­ï¸ ç„¡è³‡æ–™ï¼š{year} å¹´ {factor}")

if __name__ == "__main__":
    process_interpolated_files_stationwise()
